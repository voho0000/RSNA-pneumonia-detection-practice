{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/sovit-123/Pneumonia-Detection-using-Deep-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/rafaelpadilla/Object-Detection-Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T12:32:02.678363Z",
     "start_time": "2020-12-04T12:32:02.675122Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "\"\"\"\n",
    "Python script to prepare FasterRCNN model.\n",
    "\"\"\"\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "def model():\n",
    "    # load a pre-trained model for classification and return only the features\n",
    "    backbone = torchvision.models.densenet121(pretrained=True).features\n",
    "\n",
    "    # FasterRCNN needs to know the number of output channels in a backbone. \n",
    "    # For densenet121, it's 1024\n",
    "    backbone.out_channels = 1024\n",
    "\n",
    "    # let's make the RPN generate 5 x 3 anchors per spatial location\n",
    "    # with 5 different sizes and 3 different aspect ratios. \n",
    "    # We have a Tuple[Tuple[int]] because each feature map could potentially have different sizes and aspect ratios\n",
    "    anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
    "                                       aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "\n",
    "    # let's define what are the feature maps that we will use to perform the region of interest cropping,\n",
    "    # as well as the size of the crop after rescaling.\n",
    "    # if your backbone returns a Tensor, featmap_names is expected to be [0]. \n",
    "    # More generally, the backbone should return an OrderedDict[Tensor], \n",
    "    # and in featmap_names you can choose which feature maps to use.\n",
    "\n",
    "    roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n",
    "                                                    output_size=7,\n",
    "                                                    sampling_ratio=2)\n",
    "\n",
    "    # put the pieces together inside a FasterRCNN model\n",
    "    model = FasterRCNN(backbone,\n",
    "                       num_classes=2,\n",
    "                       rpn_anchor_generator=anchor_generator,\n",
    "                       box_roi_pool=roi_pooler)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T12:32:02.695612Z",
     "start_time": "2020-12-04T12:32:02.679252Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset.py\n",
    "\n",
    "\"\"\"\n",
    "Python script to prepare the dataset\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class RSNADataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_ids = dataframe['patientId'].unique()\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "\n",
    "        image_id = self.image_ids[index]\n",
    "        records = self.df[self.df['patientId'] == image_id]\n",
    "\n",
    "        image = cv2.imread(f'{self.image_dir}/{image_id}.png', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        boxes = records[['x', 'y', 'width', 'height']].values\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        \n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        area = torch.as_tensor(area, dtype=torch.float32)\n",
    "\n",
    "        # there is only one class\n",
    "        labels = torch.ones((records.shape[0],), dtype=torch.int64)\n",
    "        \n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        # target['masks'] = None\n",
    "        target['patientId'] = torch.tensor([index])\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': labels\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "            \n",
    "            target['boxes'] = torch.stack(tuple(map(torch.FloatTensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "\n",
    "        return image, target, image_id\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T12:32:02.702940Z",
     "start_time": "2020-12-04T12:32:02.696785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile engine.py\n",
    "\n",
    "import pandas as pd\n",
    "import dataset\n",
    "import albumentations as A\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Complete mAP code here => https://gist.github.com/tarlen5/008809c3decf19313de216b9208f3734\n",
    "\"\"\"\n",
    "\n",
    "def calculate_image_precision(gts, preds, thresholds = (0.5, ), form = 'coco') -> float:\n",
    "    # https://www.kaggle.com/sadmanaraf/wheat-detection-using-faster-rcnn-train\n",
    "    \"\"\"Calculates image precision.\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n",
    "               sorted by confidence value (descending)\n",
    "        thresholds: (float) Different thresholds\n",
    "        form: (str) Format of the coordinates\n",
    "\n",
    "    Return:\n",
    "        (float) Precision\n",
    "    \"\"\"\n",
    "    n_threshold = len(thresholds)\n",
    "    image_precision = 0.0\n",
    "    \n",
    "    ious = np.ones((len(gts), len(preds))) * -1\n",
    "    # ious = None\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        precision_at_threshold = calculate_precision(gts.copy(), preds, threshold=threshold,\n",
    "                                                     form=form, ious=ious)\n",
    "        image_precision += precision_at_threshold / n_threshold\n",
    "\n",
    "    return image_precision\n",
    "\n",
    "\n",
    "def calculate_iou(gt, pr, form='pascal_voc') -> float:\n",
    "    # https://www.kaggle.com/sadmanaraf/wheat-detection-using-faster-rcnn-train\n",
    "    \"\"\"Calculates the Intersection over Union.\n",
    "\n",
    "    Args:\n",
    "        gt: (np.ndarray[Union[int, float]]) coordinates of the ground-truth box\n",
    "        pr: (np.ndarray[Union[int, float]]) coordinates of the prdected box\n",
    "        form: (str) gt/pred coordinates format\n",
    "            - pascal_voc: [xmin, ymin, xmax, ymax]\n",
    "            - coco: [xmin, ymin, w, h]\n",
    "    Returns:\n",
    "        (float) Intersection over union (0.0 <= iou <= 1.0)\n",
    "    \"\"\"\n",
    "    if form == 'coco':\n",
    "        gt = gt.copy()\n",
    "        pr = pr.copy()\n",
    "\n",
    "        gt[2] = gt[0] + gt[2]\n",
    "        gt[3] = gt[1] + gt[3]\n",
    "        pr[2] = pr[0] + pr[2]\n",
    "        pr[3] = pr[1] + pr[3]\n",
    "\n",
    "    # Calculate overlap area\n",
    "    dx = min(gt[2], pr[2]) - max(gt[0], pr[0]) + 1\n",
    "    \n",
    "    if dx < 0:\n",
    "        return 0.0\n",
    "    dy = min(gt[3], pr[3]) - max(gt[1], pr[1]) + 1\n",
    "\n",
    "    if dy < 0:\n",
    "        return 0.0\n",
    "\n",
    "    overlap_area = dx * dy\n",
    "\n",
    "    # Calculate union area\n",
    "    union_area = (\n",
    "            (gt[2] - gt[0] + 1) * (gt[3] - gt[1] + 1) +\n",
    "            (pr[2] - pr[0] + 1) * (pr[3] - pr[1] + 1) -\n",
    "            overlap_area\n",
    "    )\n",
    "\n",
    "    return overlap_area / union_area\n",
    "\n",
    "\n",
    "def find_best_match(gts, pred, pred_idx, threshold = 0.5, form = 'pascal_voc', ious=None) -> int:\n",
    "    # https://www.kaggle.com/sadmanaraf/wheat-detection-using-faster-rcnn-train\n",
    "    \"\"\"Returns the index of the 'best match' between the\n",
    "    ground-truth boxes and the prediction. The 'best match'\n",
    "    is the highest IoU. (0.0 IoUs are ignored).\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        pred: (List[Union[int, float]]) Coordinates of the predicted box\n",
    "        pred_idx: (int) Index of the current predicted box\n",
    "        threshold: (float) Threshold\n",
    "        form: (str) Format of the coordinates\n",
    "        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n",
    "\n",
    "    Return:\n",
    "        (int) Index of the best match GT box (-1 if no match above threshold)\n",
    "    \"\"\"\n",
    "    best_match_iou = -np.inf\n",
    "    best_match_idx = -1\n",
    "    for gt_idx in range(len(gts)):\n",
    "        \n",
    "        if gts[gt_idx][0] < 0:\n",
    "            # Already matched GT-box\n",
    "            continue\n",
    "        \n",
    "        iou = -1 if ious is None else ious[gt_idx][pred_idx]\n",
    "\n",
    "        if iou < 0:\n",
    "            iou = calculate_iou(gts[gt_idx], pred, form=form)\n",
    "            \n",
    "            if ious is not None:\n",
    "                ious[gt_idx][pred_idx] = iou\n",
    "\n",
    "        if iou < threshold:\n",
    "            continue\n",
    "\n",
    "        if iou > best_match_iou:\n",
    "            best_match_iou = iou\n",
    "            best_match_idx = gt_idx\n",
    "\n",
    "    return best_match_idx\n",
    "\n",
    "def calculate_precision(gts, preds, threshold = 0.5, form = 'coco', ious=None) -> float:\n",
    "    # https://www.kaggle.com/sadmanaraf/wheat-detection-using-faster-rcnn-train\n",
    "    \"\"\"Calculates precision for GT - prediction pairs at one threshold.\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n",
    "               sorted by confidence value (descending)\n",
    "        threshold: (float) Threshold\n",
    "        form: (str) Format of the coordinates\n",
    "        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n",
    "\n",
    "    Return:\n",
    "        (float) Precision\n",
    "    \"\"\"\n",
    "    n = len(preds)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    for pred_idx in range(n):\n",
    "\n",
    "        best_match_gt_idx = find_best_match(gts, preds[pred_idx], pred_idx,\n",
    "                                            threshold=threshold, form=form, ious=ious)\n",
    "\n",
    "        if best_match_gt_idx >= 0:\n",
    "            # True positive: The predicted box matches a gt box with an IoU above the threshold.\n",
    "            tp += 1\n",
    "            # Remove the matched GT box\n",
    "            gts[best_match_gt_idx] = -1\n",
    "        else:\n",
    "            # No match\n",
    "            # False positive: indicates a predicted box had no associated gt box.\n",
    "            fp += 1\n",
    "\n",
    "    # False negative: indicates a gt box had no associated predicted box.\n",
    "    fn = (gts.sum(axis=1) > 0).sum()\n",
    "\n",
    "    return tp / (tp + fp + fn)\n",
    "\n",
    "\n",
    "# Albumentations\n",
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        A.Flip(0.5),\n",
    "        A.RandomRotate90(0.5),\n",
    "        MotionBlur(p=0.2),\n",
    "        MedianBlur(blur_limit=3, p=0.1),\n",
    "        Blur(blur_limit=3, p=0.1),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def prepare_data():\n",
    "    DIR_INPUT = '../data/size1024'\n",
    "    DIR_TRAIN = f\"{DIR_INPUT}/stage_2_train_images/\"\n",
    "\n",
    "    train_df = pd.read_csv(f\"{DIR_INPUT}/class_box_df.csv\")\n",
    "    print(train_df.shape)\n",
    "    train_df.head()\n",
    "\n",
    "    train_df_pos = pd.DataFrame(columns=['patientId', 'x', 'y', 'width', 'height'])\n",
    "\n",
    "    k = 0\n",
    "    for i in range(len(train_df)):\n",
    "        if train_df.loc[i]['Target'] == 1:\n",
    "            train_df_pos.loc[k] = train_df.loc[i]\n",
    "            k += 1\n",
    "\n",
    "    image_ids = train_df_pos['patientId'].unique()\n",
    "    valid_ids = image_ids[-300:]\n",
    "    train_ids = image_ids[:-300]\n",
    "    print(f\"Training instance: {len(train_ids)}\")\n",
    "    print(f\"Validation instances: {len(valid_ids)}\")\n",
    "\n",
    "    valid_df = train_df_pos[train_df_pos['patientId'].isin(valid_ids)]\n",
    "    train_df = train_df_pos[train_df_pos['patientId'].isin(train_ids)]\n",
    "\n",
    "    valid_df.shape, train_df.shape\n",
    "    \n",
    "    train_dataset = dataset.RSNADataset(train_df, DIR_TRAIN, get_train_transform())\n",
    "    valid_dataset = dataset.RSNADataset(valid_df, DIR_TRAIN, get_valid_transform())\n",
    "    \n",
    "    return train_dataset, valid_dataset\n",
    "    \n",
    "def get_data_loader(batch_size):\n",
    "    \n",
    "    train_dataset, valid_dataset = prepare_data()\n",
    "    \n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4, # else showing broken pipe error\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    valid_data_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4, # else showing broken pipe error\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    return train_data_loader, valid_data_loader\n",
    "\n",
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "        \n",
    "def train(dataloader, lr_scheduler, model, optimizer, \n",
    "          device, epoch, loss_hist, itr):\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    loss_hist.reset()\n",
    "    for images, targets, image_ids in dataloader:\n",
    "        \n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "\n",
    "        loss_hist.send(loss_value)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if itr % 50 == 0:\n",
    "            print(f\"Epoch #{epoch} iteration #{itr} loss: {loss_value}\")\n",
    "\n",
    "        itr += 1\n",
    "    \n",
    "    end = time.time()\n",
    "    return loss_hist, end, start\n",
    "\n",
    "def validate(dataloader, model, device, iou_thresholds):\n",
    "    valid_image_precision = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets, image_ids in dataloader:\n",
    "\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            outputs = model(images)\n",
    "            \n",
    "    for i, image in enumerate(images):\n",
    "        boxes = outputs[i]['boxes'].data.cpu().numpy()\n",
    "        scores = outputs[i]['scores'].data.cpu().numpy()\n",
    "        gt_boxes = targets[i]['boxes'].cpu().numpy()\n",
    "        preds_sorted_idx = np.argsort(scores)[::-1]\n",
    "        preds_sorted = boxes[preds_sorted_idx]\n",
    "        image_precision = calculate_image_precision(preds_sorted,\n",
    "                                                        gt_boxes,\n",
    "                                                        thresholds=iou_thresholds,\n",
    "                                                        form='coco')\n",
    "        valid_image_precision.append(image_precision)\n",
    "\n",
    "    valid_prec = np.mean(valid_image_precision)\n",
    "    return valid_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T12:32:20.901929Z",
     "start_time": "2020-12-04T12:32:20.897796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import torch\n",
    "import engine\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "from engine import get_data_loader, Averager, train, validate\n",
    "from model import model\n",
    "# from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-s', '--show-sample', dest='show_sample', default='no', \n",
    "                 help='whether to visualize a wheat sample with bboxes or not')\n",
    "args = vars(parser.parse_args())\n",
    "\n",
    "# learning parameters\n",
    "num_epochs = 30\n",
    "lr = 0.001\n",
    "batch_size = 4\n",
    "\n",
    "model = model().to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=lr, momentum=0.9, weight_decay=0.0005)\n",
    "# optimizer = torch.optim.Adam(params, lr=0.01)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "lr_scheduler = None\n",
    "\n",
    "# initialize the Averager\n",
    "loss_hist = engine.Averager()\n",
    "# get the dataloader\n",
    "train_data_loader, valid_data_loader = get_data_loader(batch_size)\n",
    "\n",
    "if args['show_sample'] == 'yes':\n",
    "    images, targets, image_ids = next(iter(train_data_loader))\n",
    "    images = list(image.to(device) for image in images)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    boxes = targets[2]['boxes'].cpu().numpy().astype(np.int32)\n",
    "    sample = images[2].permute(1,2,0).cpu().numpy()\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "    for box in boxes:\n",
    "        cv2.rectangle(sample,\n",
    "                      (box[0], box[1]),\n",
    "                      (box[2], box[3]),\n",
    "                      (220, 0, 0), 3)\n",
    "    \n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(sample)\n",
    "    plt.show()\n",
    "\n",
    "iou_thresholds = [x for x in np.arange(0.5, 0.76, 0.05)]\n",
    "\n",
    "train_loss = []\n",
    "precision = []\n",
    "for epoch in range(num_epochs):\n",
    "    itr = 1\n",
    "    train_loss_hist, end, start = train(train_data_loader, lr_scheduler,\n",
    "                                        model, optimizer, device,\n",
    "                                        epoch, loss_hist, itr)\n",
    "    valid_prec = validate(valid_data_loader, model, device, iou_thresholds)\n",
    "    print(f\"Took {(end-start)/60:.3f} minutes for epoch# {epoch} to train\")\n",
    "    print(f\"Epoch #{epoch} Train loss: {train_loss_hist.value}\")  \n",
    "    print(f\"Epoch #{epoch} Validation Precision: {valid_prec}\")  \n",
    "    train_loss.append(train_loss_hist.value)\n",
    "    precision.append(valid_prec)\n",
    "    \n",
    "    # update the learning rate\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "torch.save(model.state_dict(), 'fasterrcnn_densenet121_fpn.pth')\n",
    "\n",
    "# plot and save the training loss\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('loss.png')\n",
    "\n",
    "# plot and save the validation precision\n",
    "plt.figure()\n",
    "plt.plot(precision, label='Validation precision')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('precision.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T16:39:43.955536Z",
     "start_time": "2020-12-04T12:32:21.513125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30227, 8)\n",
      "Training instance: 5712\n",
      "Validation instances: 300\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Figure(1600x800)\n",
      "/home/yihsin/anaconda3/lib/python3.7/site-packages/torchvision/ops/boxes.py:101: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  keep = keep.nonzero().squeeze(1)\n",
      "Epoch #0 iteration #50 loss: 0.4258514940738678\n",
      "Epoch #0 iteration #100 loss: 0.4065609574317932\n",
      "Epoch #0 iteration #150 loss: 0.08959832042455673\n",
      "Epoch #0 iteration #200 loss: 0.36938703060150146\n",
      "Epoch #0 iteration #250 loss: 0.3175070881843567\n",
      "Epoch #0 iteration #300 loss: 0.3935111463069916\n",
      "Epoch #0 iteration #350 loss: 0.2277427464723587\n",
      "Epoch #0 iteration #400 loss: 0.3326404392719269\n",
      "Epoch #0 iteration #450 loss: 0.24050237238407135\n",
      "Epoch #0 iteration #500 loss: 0.150182843208313\n",
      "Epoch #0 iteration #550 loss: 0.26465994119644165\n",
      "Epoch #0 iteration #600 loss: 0.12723317742347717\n",
      "Epoch #0 iteration #650 loss: 0.3307698965072632\n",
      "Epoch #0 iteration #700 loss: 0.2536562383174896\n",
      "Epoch #0 iteration #750 loss: 0.24628177285194397\n",
      "Epoch #0 iteration #800 loss: 0.2639564573764801\n",
      "Epoch #0 iteration #850 loss: 0.23770546913146973\n",
      "Epoch #0 iteration #900 loss: 0.2933872640132904\n",
      "Epoch #0 iteration #950 loss: 0.18903668224811554\n",
      "Epoch #0 iteration #1000 loss: 0.25624537467956543\n",
      "Epoch #0 iteration #1050 loss: 0.24660207331180573\n",
      "Epoch #0 iteration #1100 loss: 0.27258771657943726\n",
      "Epoch #0 iteration #1150 loss: 0.3313465118408203\n",
      "Epoch #0 iteration #1200 loss: 0.2634841203689575\n",
      "Epoch #0 iteration #1250 loss: 0.17184846103191376\n",
      "Epoch #0 iteration #1300 loss: 0.2749253213405609\n",
      "Epoch #0 iteration #1350 loss: 0.17562797665596008\n",
      "Epoch #0 iteration #1400 loss: 0.1775631606578827\n",
      "Took 8.021 minutes for epoch# 0 to train\n",
      "Epoch #0 Train loss: 0.2630062779041232\n",
      "Epoch #0 Validation Precision: 0.1325831475287997\n",
      "Epoch #1 iteration #50 loss: 0.2767893075942993\n",
      "Epoch #1 iteration #100 loss: 0.22643956542015076\n",
      "Epoch #1 iteration #150 loss: 0.1250397115945816\n",
      "Epoch #1 iteration #200 loss: 0.2070547491312027\n",
      "Epoch #1 iteration #250 loss: 0.24987244606018066\n",
      "Epoch #1 iteration #300 loss: 0.23674844205379486\n",
      "Epoch #1 iteration #350 loss: 0.23158709704875946\n",
      "Epoch #1 iteration #400 loss: 0.2679380476474762\n",
      "Epoch #1 iteration #450 loss: 0.24667924642562866\n",
      "Epoch #1 iteration #500 loss: 0.13033229112625122\n",
      "Epoch #1 iteration #550 loss: 0.25172147154808044\n",
      "Epoch #1 iteration #600 loss: 0.14504985511302948\n",
      "Epoch #1 iteration #650 loss: 0.30909401178359985\n",
      "Epoch #1 iteration #700 loss: 0.17883539199829102\n",
      "Epoch #1 iteration #750 loss: 0.29286250472068787\n",
      "Epoch #1 iteration #800 loss: 0.20805421471595764\n",
      "Epoch #1 iteration #850 loss: 0.2193077653646469\n",
      "Epoch #1 iteration #900 loss: 0.2474895715713501\n",
      "Epoch #1 iteration #950 loss: 0.20628003776073456\n",
      "Epoch #1 iteration #1000 loss: 0.23129436373710632\n",
      "Epoch #1 iteration #1050 loss: 0.21726100146770477\n",
      "Epoch #1 iteration #1100 loss: 0.23723751306533813\n",
      "Epoch #1 iteration #1150 loss: 0.3044887185096741\n",
      "Epoch #1 iteration #1200 loss: 0.2445540726184845\n",
      "Epoch #1 iteration #1250 loss: 0.2183333933353424\n",
      "Epoch #1 iteration #1300 loss: 0.2740381360054016\n",
      "Epoch #1 iteration #1350 loss: 0.1567251831293106\n",
      "Epoch #1 iteration #1400 loss: 0.1807202845811844\n",
      "Took 8.004 minutes for epoch# 1 to train\n",
      "Epoch #1 Train loss: 0.21942532689673225\n",
      "Epoch #1 Validation Precision: 0.18363603988603988\n",
      "Epoch #2 iteration #50 loss: 0.26607927680015564\n",
      "Epoch #2 iteration #100 loss: 0.22469554841518402\n",
      "Epoch #2 iteration #150 loss: 0.11847639083862305\n",
      "Epoch #2 iteration #200 loss: 0.18553510308265686\n",
      "Epoch #2 iteration #250 loss: 0.20323476195335388\n",
      "Epoch #2 iteration #300 loss: 0.25085699558258057\n",
      "Epoch #2 iteration #350 loss: 0.2312546819448471\n",
      "Epoch #2 iteration #400 loss: 0.29101625084877014\n",
      "Epoch #2 iteration #450 loss: 0.22518067061901093\n",
      "Epoch #2 iteration #500 loss: 0.12920907139778137\n",
      "Epoch #2 iteration #550 loss: 0.24091868102550507\n",
      "Epoch #2 iteration #600 loss: 0.1255698949098587\n",
      "Epoch #2 iteration #650 loss: 0.30782535672187805\n",
      "Epoch #2 iteration #700 loss: 0.17018058896064758\n",
      "Epoch #2 iteration #750 loss: 0.24569441378116608\n",
      "Epoch #2 iteration #800 loss: 0.2197408229112625\n",
      "Epoch #2 iteration #850 loss: 0.2139340043067932\n",
      "Epoch #2 iteration #900 loss: 0.243760883808136\n",
      "Epoch #2 iteration #950 loss: 0.19167432188987732\n",
      "Epoch #2 iteration #1000 loss: 0.20979206264019012\n",
      "Epoch #2 iteration #1050 loss: 0.19212175905704498\n",
      "Epoch #2 iteration #1100 loss: 0.2511971890926361\n",
      "Epoch #2 iteration #1150 loss: 0.24568644165992737\n",
      "Epoch #2 iteration #1200 loss: 0.2438366413116455\n",
      "Epoch #2 iteration #1250 loss: 0.1946684867143631\n",
      "Epoch #2 iteration #1300 loss: 0.2917823791503906\n",
      "Epoch #2 iteration #1350 loss: 0.15531034767627716\n",
      "Epoch #2 iteration #1400 loss: 0.19524455070495605\n",
      "Took 8.033 minutes for epoch# 2 to train\n",
      "Epoch #2 Train loss: 0.21490484023732798\n",
      "Epoch #2 Validation Precision: 0.14394355644355644\n",
      "Epoch #3 iteration #50 loss: 0.26709744334220886\n",
      "Epoch #3 iteration #100 loss: 0.22786197066307068\n",
      "Epoch #3 iteration #150 loss: 0.1389499008655548\n",
      "Epoch #3 iteration #200 loss: 0.213853120803833\n",
      "Epoch #3 iteration #250 loss: 0.2061641812324524\n",
      "Epoch #3 iteration #300 loss: 0.23047682642936707\n",
      "Epoch #3 iteration #350 loss: 0.17027513682842255\n",
      "Epoch #3 iteration #400 loss: 0.23457464575767517\n",
      "Epoch #3 iteration #450 loss: 0.22373467683792114\n",
      "Epoch #3 iteration #500 loss: 0.12852533161640167\n",
      "Epoch #3 iteration #550 loss: 0.26088595390319824\n",
      "Epoch #3 iteration #600 loss: 0.1250794231891632\n",
      "Epoch #3 iteration #650 loss: 0.31352344155311584\n",
      "Epoch #3 iteration #700 loss: 0.1573263704776764\n",
      "Epoch #3 iteration #750 loss: 0.2513332962989807\n",
      "Epoch #3 iteration #1150 loss: 0.2284473329782486\n",
      "Epoch #3 iteration #1200 loss: 0.2244013249874115\n",
      "Epoch #3 iteration #1250 loss: 0.19323982298374176\n",
      "Epoch #3 iteration #1300 loss: 0.27520063519477844\n",
      "Epoch #3 iteration #1350 loss: 0.15308310091495514\n",
      "Epoch #3 iteration #1400 loss: 0.20289061963558197\n",
      "Took 8.039 minutes for epoch# 3 to train\n",
      "Epoch #3 Train loss: 0.21251171669226235\n",
      "Epoch #3 Validation Precision: 0.1954545454545455\n",
      "Epoch #4 iteration #50 loss: 0.25670135021209717\n",
      "Epoch #4 iteration #100 loss: 0.19232848286628723\n",
      "Epoch #4 iteration #150 loss: 0.14030514657497406\n",
      "Epoch #4 iteration #200 loss: 0.18102949857711792\n",
      "Epoch #4 iteration #250 loss: 0.20654892921447754\n",
      "Epoch #4 iteration #300 loss: 0.1983216106891632\n",
      "Epoch #4 iteration #350 loss: 0.21619156002998352\n",
      "Epoch #4 iteration #400 loss: 0.2514209747314453\n",
      "Epoch #4 iteration #450 loss: 0.2657388746738434\n",
      "Epoch #4 iteration #500 loss: 0.12849919497966766\n",
      "Epoch #4 iteration #550 loss: 0.2616387903690338\n",
      "Epoch #4 iteration #600 loss: 0.1429537683725357\n",
      "Epoch #4 iteration #650 loss: 0.3105602562427521\n",
      "Epoch #4 iteration #700 loss: 0.1736789047718048\n",
      "Epoch #4 iteration #750 loss: 0.21662817895412445\n",
      "Epoch #4 iteration #800 loss: 0.21836070716381073\n",
      "Epoch #4 iteration #850 loss: 0.21632765233516693\n",
      "Epoch #4 iteration #900 loss: 0.25191792845726013\n",
      "Epoch #4 iteration #950 loss: 0.16362780332565308\n",
      "Epoch #4 iteration #1000 loss: 0.21239525079727173\n",
      "Epoch #4 iteration #1050 loss: 0.21908673644065857\n",
      "Epoch #4 iteration #1100 loss: 0.2490958422422409\n",
      "Epoch #4 iteration #1150 loss: 0.2534337639808655\n",
      "Epoch #4 iteration #1200 loss: 0.23579944670200348\n",
      "Epoch #4 iteration #1250 loss: 0.18024185299873352\n",
      "Epoch #4 iteration #1300 loss: 0.2563330829143524\n",
      "Epoch #4 iteration #1350 loss: 0.1598612666130066\n",
      "Epoch #4 iteration #1400 loss: 0.1907655894756317\n",
      "Took 8.212 minutes for epoch# 4 to train\n",
      "Epoch #4 Train loss: 0.21045359742699885\n",
      "Epoch #4 Validation Precision: 0.17980089763177998\n",
      "Epoch #5 iteration #50 loss: 0.2514670789241791\n",
      "Epoch #5 iteration #100 loss: 0.2195931077003479\n",
      "Epoch #5 iteration #150 loss: 0.1606069654226303\n",
      "Epoch #5 iteration #200 loss: 0.1929342895746231\n",
      "Epoch #5 iteration #250 loss: 0.20292645692825317\n",
      "Epoch #5 iteration #300 loss: 0.20637571811676025\n",
      "Epoch #5 iteration #350 loss: 0.1815107762813568\n",
      "Epoch #5 iteration #400 loss: 0.2579815685749054\n",
      "Epoch #5 iteration #450 loss: 0.23230411112308502\n",
      "Epoch #5 iteration #500 loss: 0.15626084804534912\n",
      "Epoch #5 iteration #550 loss: 0.2709657847881317\n",
      "Epoch #5 iteration #600 loss: 0.1411588490009308\n",
      "Epoch #5 iteration #650 loss: 0.2980038821697235\n",
      "Epoch #5 iteration #700 loss: 0.14287486672401428\n",
      "Epoch #5 iteration #750 loss: 0.2413059026002884\n",
      "Epoch #5 iteration #800 loss: 0.21764107048511505\n",
      "Epoch #5 iteration #850 loss: 0.20353786647319794\n",
      "Epoch #5 iteration #900 loss: 0.20680341124534607\n",
      "Epoch #5 iteration #950 loss: 0.19017431139945984\n",
      "Epoch #5 iteration #1000 loss: 0.20638643205165863\n",
      "Epoch #5 iteration #1050 loss: 0.18382114171981812\n",
      "Epoch #5 iteration #1100 loss: 0.20657140016555786\n",
      "Epoch #5 iteration #1150 loss: 0.24043786525726318\n",
      "Epoch #5 iteration #1200 loss: 0.20696507394313812\n",
      "Epoch #5 iteration #1250 loss: 0.16539528965950012\n",
      "Epoch #5 iteration #1300 loss: 0.27566447854042053\n",
      "Epoch #5 iteration #1350 loss: 0.17188793420791626\n",
      "Epoch #5 iteration #1400 loss: 0.1845483034849167\n",
      "Took 8.094 minutes for epoch# 5 to train\n",
      "Epoch #5 Train loss: 0.20786023272477946\n",
      "Epoch #5 Validation Precision: 0.2016895141895142\n",
      "Epoch #6 iteration #50 loss: 0.2782253921031952\n",
      "Epoch #6 iteration #100 loss: 0.1988290697336197\n",
      "Epoch #6 iteration #150 loss: 0.11920647323131561\n",
      "Epoch #6 iteration #200 loss: 0.16614358127117157\n",
      "Epoch #6 iteration #250 loss: 0.2219168245792389\n",
      "Epoch #6 iteration #300 loss: 0.17255425453186035\n",
      "Epoch #6 iteration #350 loss: 0.2025875598192215\n",
      "Epoch #6 iteration #400 loss: 0.25611311197280884\n",
      "Epoch #6 iteration #450 loss: 0.24225777387619019\n",
      "Epoch #6 iteration #500 loss: 0.1327291578054428\n",
      "Epoch #6 iteration #550 loss: 0.26786988973617554\n",
      "Epoch #6 iteration #600 loss: 0.15035787224769592\n",
      "Epoch #6 iteration #650 loss: 0.30681896209716797\n",
      "Epoch #6 iteration #700 loss: 0.1539691984653473\n",
      "Epoch #6 iteration #750 loss: 0.21641336381435394\n",
      "Epoch #6 iteration #800 loss: 0.18357126414775848\n",
      "Epoch #6 iteration #850 loss: 0.19589653611183167\n",
      "Epoch #6 iteration #900 loss: 0.22300250828266144\n",
      "Epoch #6 iteration #950 loss: 0.1885243058204651\n",
      "Epoch #6 iteration #1000 loss: 0.2042657732963562\n",
      "Epoch #6 iteration #1050 loss: 0.20974203944206238\n",
      "Epoch #6 iteration #1100 loss: 0.21518893539905548\n",
      "Epoch #6 iteration #1150 loss: 0.2660314440727234\n",
      "Epoch #6 iteration #1200 loss: 0.20700612664222717\n",
      "Epoch #6 iteration #1250 loss: 0.18859459459781647\n",
      "Epoch #6 iteration #1300 loss: 0.2681789994239807\n",
      "Epoch #6 iteration #1350 loss: 0.1651853322982788\n",
      "Epoch #6 iteration #1400 loss: 0.1836361438035965\n",
      "Took 8.107 minutes for epoch# 6 to train\n",
      "Epoch #6 Train loss: 0.20755978320993962\n",
      "Epoch #6 Validation Precision: 0.19748931623931626\n",
      "Epoch #7 iteration #50 loss: 0.2563888132572174\n",
      "Epoch #7 iteration #100 loss: 0.22875042259693146\n",
      "Epoch #7 iteration #150 loss: 0.14626985788345337\n",
      "Epoch #7 iteration #200 loss: 0.1921727955341339\n",
      "Epoch #7 iteration #250 loss: 0.18575870990753174\n",
      "Epoch #7 iteration #300 loss: 0.17767591774463654\n",
      "Epoch #7 iteration #350 loss: 0.20878589153289795\n",
      "Epoch #7 iteration #400 loss: 0.22799639403820038\n",
      "Epoch #7 iteration #450 loss: 0.19692029058933258\n",
      "Epoch #7 iteration #500 loss: 0.13405649363994598\n",
      "Epoch #7 iteration #550 loss: 0.2402416467666626\n",
      "Epoch #7 iteration #600 loss: 0.1277051866054535\n",
      "Epoch #7 iteration #650 loss: 0.3075454533100128\n",
      "Epoch #7 iteration #700 loss: 0.13817858695983887\n",
      "Epoch #7 iteration #750 loss: 0.22507497668266296\n",
      "Epoch #7 iteration #800 loss: 0.184381902217865\n",
      "Epoch #7 iteration #850 loss: 0.19393134117126465\n",
      "Epoch #7 iteration #900 loss: 0.2190362811088562\n",
      "Epoch #7 iteration #950 loss: 0.17250598967075348\n",
      "Epoch #7 iteration #1000 loss: 0.19032210111618042\n",
      "Epoch #7 iteration #1050 loss: 0.2075643390417099\n",
      "Epoch #7 iteration #1100 loss: 0.19776172935962677\n",
      "Epoch #7 iteration #1150 loss: 0.23197318613529205\n",
      "Epoch #7 iteration #1200 loss: 0.21823495626449585\n",
      "Epoch #7 iteration #1250 loss: 0.1989932805299759\n",
      "Epoch #7 iteration #1300 loss: 0.2660976052284241\n",
      "Epoch #7 iteration #1350 loss: 0.13919825851917267\n",
      "Epoch #7 iteration #1400 loss: 0.18834088742733002\n",
      "Took 8.100 minutes for epoch# 7 to train\n",
      "Epoch #7 Train loss: 0.20635079622206068\n",
      "Epoch #7 Validation Precision: 0.20369352869352866\n",
      "Epoch #8 iteration #50 loss: 0.2641672194004059\n",
      "Epoch #8 iteration #100 loss: 0.2017555832862854\n",
      "Epoch #8 iteration #150 loss: 0.13176266849040985\n",
      "Epoch #8 iteration #200 loss: 0.1883290410041809\n",
      "Epoch #8 iteration #250 loss: 0.202167809009552\n",
      "Epoch #8 iteration #300 loss: 0.18751049041748047\n",
      "Epoch #8 iteration #350 loss: 0.1987418234348297\n",
      "Epoch #8 iteration #400 loss: 0.23921898007392883\n",
      "Epoch #8 iteration #450 loss: 0.19876645505428314\n",
      "Epoch #8 iteration #500 loss: 0.13977351784706116\n",
      "Epoch #8 iteration #550 loss: 0.23887082934379578\n",
      "Epoch #8 iteration #600 loss: 0.1498933583498001\n",
      "Epoch #8 iteration #650 loss: 0.3047439157962799\n",
      "Epoch #8 iteration #700 loss: 0.12231643497943878\n",
      "Epoch #8 iteration #750 loss: 0.23391327261924744\n",
      "Epoch #8 iteration #800 loss: 0.20083209872245789\n",
      "Epoch #8 iteration #850 loss: 0.1950652301311493\n",
      "Epoch #8 iteration #900 loss: 0.22587698698043823\n",
      "Epoch #8 iteration #950 loss: 0.19254755973815918\n",
      "Epoch #8 iteration #1000 loss: 0.19741246104240417\n",
      "Epoch #8 iteration #1050 loss: 0.2056596875190735\n",
      "Epoch #8 iteration #1100 loss: 0.21271264553070068\n",
      "Epoch #8 iteration #1150 loss: 0.27630215883255005\n",
      "Epoch #8 iteration #1200 loss: 0.25189951062202454\n",
      "Epoch #8 iteration #1250 loss: 0.17807838320732117\n",
      "Epoch #8 iteration #1300 loss: 0.2595160901546478\n",
      "Epoch #8 iteration #1350 loss: 0.15358737111091614\n",
      "Epoch #8 iteration #1400 loss: 0.20306505262851715\n",
      "Took 8.114 minutes for epoch# 8 to train\n",
      "Epoch #8 Train loss: 0.20480686557121805\n",
      "Epoch #8 Validation Precision: 0.2007783882783883\n",
      "Epoch #9 iteration #50 loss: 0.2424405962228775\n",
      "Epoch #9 iteration #100 loss: 0.18010738492012024\n",
      "Epoch #9 iteration #150 loss: 0.13943783938884735\n",
      "Epoch #9 iteration #200 loss: 0.20034611225128174\n",
      "Epoch #9 iteration #250 loss: 0.17024362087249756\n",
      "Epoch #9 iteration #300 loss: 0.16750065982341766\n",
      "Epoch #9 iteration #350 loss: 0.19435399770736694\n",
      "Epoch #9 iteration #400 loss: 0.23653243482112885\n",
      "Epoch #9 iteration #450 loss: 0.1957744061946869\n",
      "Epoch #9 iteration #500 loss: 0.13687047362327576\n",
      "Epoch #9 iteration #550 loss: 0.23669429123401642\n",
      "Epoch #9 iteration #600 loss: 0.1335773915052414\n",
      "Epoch #9 iteration #650 loss: 0.28877267241477966\n",
      "Epoch #9 iteration #700 loss: 0.14092768728733063\n",
      "Epoch #9 iteration #750 loss: 0.2304050475358963\n",
      "Epoch #9 iteration #800 loss: 0.19370287656784058\n",
      "Epoch #9 iteration #850 loss: 0.19184790551662445\n",
      "Epoch #9 iteration #900 loss: 0.21699318289756775\n",
      "Epoch #9 iteration #950 loss: 0.16246338188648224\n",
      "Epoch #9 iteration #1000 loss: 0.19981825351715088\n",
      "Epoch #9 iteration #1050 loss: 0.20986422896385193\n",
      "Epoch #9 iteration #1100 loss: 0.23466867208480835\n",
      "Epoch #9 iteration #1150 loss: 0.2527279555797577\n",
      "Epoch #9 iteration #1200 loss: 0.19696341454982758\n",
      "Epoch #9 iteration #1250 loss: 0.2122495323419571\n",
      "Epoch #9 iteration #1300 loss: 0.2666655480861664\n",
      "Epoch #9 iteration #1350 loss: 0.14865098893642426\n",
      "Epoch #9 iteration #1400 loss: 0.18658921122550964\n",
      "Took 8.103 minutes for epoch# 9 to train\n",
      "Epoch #9 Train loss: 0.20320440139047571\n",
      "Epoch #9 Validation Precision: 0.20707070707070707\n",
      "Epoch #10 iteration #50 loss: 0.28553736209869385\n",
      "Epoch #10 iteration #100 loss: 0.17378564178943634\n",
      "Epoch #10 iteration #150 loss: 0.13153576850891113\n",
      "Epoch #10 iteration #200 loss: 0.18206578493118286\n",
      "Epoch #10 iteration #250 loss: 0.17844682931900024\n",
      "Epoch #10 iteration #300 loss: 0.1645996868610382\n",
      "Epoch #10 iteration #350 loss: 0.19668765366077423\n",
      "Epoch #10 iteration #400 loss: 0.2114720642566681\n",
      "Epoch #10 iteration #450 loss: 0.22217059135437012\n",
      "Epoch #10 iteration #500 loss: 0.12536674737930298\n",
      "Epoch #10 iteration #550 loss: 0.24382439255714417\n",
      "Epoch #10 iteration #600 loss: 0.16049832105636597\n",
      "Epoch #10 iteration #650 loss: 0.2843080163002014\n",
      "Epoch #10 iteration #700 loss: 0.12289288640022278\n",
      "Epoch #10 iteration #750 loss: 0.24988718330860138\n",
      "Epoch #10 iteration #800 loss: 0.1837019920349121\n",
      "Epoch #10 iteration #850 loss: 0.19792407751083374\n",
      "Epoch #10 iteration #900 loss: 0.20827963948249817\n",
      "Epoch #10 iteration #950 loss: 0.17729789018630981\n",
      "Epoch #10 iteration #1000 loss: 0.19351018965244293\n",
      "Epoch #10 iteration #1050 loss: 0.18283188343048096\n",
      "Epoch #10 iteration #1100 loss: 0.18725547194480896\n",
      "Epoch #10 iteration #1150 loss: 0.22830694913864136\n",
      "Epoch #10 iteration #1200 loss: 0.2152119129896164\n",
      "Epoch #10 iteration #1250 loss: 0.19632570445537567\n",
      "Epoch #10 iteration #1300 loss: 0.25272032618522644\n",
      "Epoch #10 iteration #1350 loss: 0.12996584177017212\n",
      "Epoch #10 iteration #1400 loss: 0.1917974203824997\n",
      "Took 8.096 minutes for epoch# 10 to train\n",
      "Epoch #10 Train loss: 0.20282316590849758\n",
      "Epoch #10 Validation Precision: 0.26458333333333334\n",
      "Epoch #11 iteration #50 loss: 0.2621051073074341\n",
      "Epoch #11 iteration #100 loss: 0.17390596866607666\n",
      "Epoch #11 iteration #150 loss: 0.12028130888938904\n",
      "Epoch #11 iteration #200 loss: 0.19440299272537231\n",
      "Epoch #11 iteration #250 loss: 0.18823610246181488\n",
      "Epoch #11 iteration #300 loss: 0.17516863346099854\n",
      "Epoch #11 iteration #350 loss: 0.17802171409130096\n",
      "Epoch #11 iteration #400 loss: 0.23563143610954285\n",
      "Epoch #11 iteration #450 loss: 0.23482467234134674\n",
      "Epoch #11 iteration #500 loss: 0.13154368102550507\n",
      "Epoch #11 iteration #550 loss: 0.23060838878154755\n",
      "Epoch #11 iteration #600 loss: 0.15464764833450317\n",
      "Epoch #11 iteration #650 loss: 0.3589777648448944\n",
      "Epoch #11 iteration #700 loss: 0.1250167191028595\n",
      "Epoch #11 iteration #750 loss: 0.259600967168808\n",
      "Epoch #11 iteration #800 loss: 0.21022996306419373\n",
      "Epoch #11 iteration #850 loss: 0.1862976998090744\n",
      "Epoch #11 iteration #900 loss: 0.21794429421424866\n",
      "Epoch #11 iteration #950 loss: 0.16742469370365143\n",
      "Epoch #11 iteration #1000 loss: 0.20729734003543854\n",
      "Epoch #11 iteration #1050 loss: 0.20284761488437653\n",
      "Epoch #11 iteration #1100 loss: 0.21764875948429108\n",
      "Epoch #11 iteration #1150 loss: 0.2495175004005432\n",
      "Epoch #11 iteration #1200 loss: 0.2054637223482132\n",
      "Epoch #11 iteration #1250 loss: 0.16529648005962372\n",
      "Epoch #11 iteration #1300 loss: 0.2767515182495117\n",
      "Epoch #11 iteration #1350 loss: 0.138161301612854\n",
      "Epoch #11 iteration #1400 loss: 0.18296575546264648\n",
      "Took 8.087 minutes for epoch# 11 to train\n",
      "Epoch #11 Train loss: 0.20178573917211437\n",
      "Epoch #11 Validation Precision: 0.23657407407407405\n",
      "Epoch #12 iteration #50 loss: 0.24459128081798553\n",
      "Epoch #12 iteration #100 loss: 0.17497359216213226\n",
      "Epoch #12 iteration #150 loss: 0.1333196610212326\n",
      "Epoch #12 iteration #200 loss: 0.19017182290554047\n",
      "Epoch #12 iteration #250 loss: 0.19915571808815002\n",
      "Epoch #12 iteration #300 loss: 0.16341404616832733\n",
      "Epoch #12 iteration #350 loss: 0.1755353957414627\n",
      "Epoch #12 iteration #400 loss: 0.23007868230342865\n",
      "Epoch #12 iteration #450 loss: 0.17532655596733093\n",
      "Epoch #12 iteration #500 loss: 0.1317506730556488\n",
      "Epoch #12 iteration #550 loss: 0.24930523335933685\n",
      "Epoch #12 iteration #600 loss: 0.1494085043668747\n",
      "Epoch #12 iteration #650 loss: 0.28911539912223816\n",
      "Epoch #12 iteration #700 loss: 0.13027191162109375\n",
      "Epoch #12 iteration #750 loss: 0.2193375825881958\n",
      "Epoch #12 iteration #800 loss: 0.17735221982002258\n",
      "Epoch #12 iteration #850 loss: 0.17574484646320343\n",
      "Epoch #12 iteration #900 loss: 0.2274138331413269\n",
      "Epoch #12 iteration #950 loss: 0.16972245275974274\n",
      "Epoch #12 iteration #1000 loss: 0.22762201726436615\n",
      "Epoch #12 iteration #1050 loss: 0.1790609210729599\n",
      "Epoch #12 iteration #1100 loss: 0.20518246293067932\n",
      "Epoch #12 iteration #1150 loss: 0.2730158567428589\n",
      "Epoch #12 iteration #1200 loss: 0.22102715075016022\n",
      "Epoch #12 iteration #1250 loss: 0.1747463345527649\n",
      "Epoch #12 iteration #1300 loss: 0.2815585136413574\n",
      "Epoch #12 iteration #1350 loss: 0.11002664268016815\n",
      "Epoch #12 iteration #1400 loss: 0.20021449029445648\n",
      "Took 8.078 minutes for epoch# 12 to train\n",
      "Epoch #12 Train loss: 0.20062639164093996\n",
      "Epoch #12 Validation Precision: 0.2248196248196248\n",
      "Epoch #13 iteration #50 loss: 0.22804823517799377\n",
      "Epoch #13 iteration #100 loss: 0.2118796855211258\n",
      "Epoch #13 iteration #150 loss: 0.12917077541351318\n",
      "Epoch #13 iteration #200 loss: 0.20472483336925507\n",
      "Epoch #13 iteration #250 loss: 0.18808655440807343\n",
      "Epoch #13 iteration #300 loss: 0.1793064922094345\n",
      "Epoch #13 iteration #350 loss: 0.19042649865150452\n",
      "Epoch #13 iteration #400 loss: 0.22105035185813904\n",
      "Epoch #13 iteration #450 loss: 0.2028794139623642\n",
      "Epoch #13 iteration #500 loss: 0.11882933974266052\n",
      "Epoch #13 iteration #550 loss: 0.257468581199646\n",
      "Epoch #13 iteration #600 loss: 0.13581472635269165\n",
      "Epoch #13 iteration #650 loss: 0.31190255284309387\n",
      "Epoch #13 iteration #700 loss: 0.13984115421772003\n",
      "Epoch #13 iteration #750 loss: 0.26302188634872437\n",
      "Epoch #13 iteration #800 loss: 0.20203693211078644\n",
      "Epoch #13 iteration #850 loss: 0.2046540528535843\n",
      "Epoch #13 iteration #900 loss: 0.17560166120529175\n",
      "Epoch #13 iteration #950 loss: 0.16069747507572174\n",
      "Epoch #13 iteration #1000 loss: 0.2218978852033615\n",
      "Epoch #13 iteration #1050 loss: 0.18930022418498993\n",
      "Epoch #13 iteration #1100 loss: 0.1894233673810959\n",
      "Epoch #13 iteration #1150 loss: 0.2399260699748993\n",
      "Epoch #13 iteration #1200 loss: 0.21702535450458527\n",
      "Epoch #13 iteration #1250 loss: 0.19169938564300537\n",
      "Epoch #13 iteration #1300 loss: 0.2475639283657074\n",
      "Epoch #13 iteration #1350 loss: 0.1544099599123001\n",
      "Epoch #13 iteration #1400 loss: 0.19041168689727783\n",
      "Took 8.095 minutes for epoch# 13 to train\n",
      "Epoch #13 Train loss: 0.20047105501825904\n",
      "Epoch #13 Validation Precision: 0.20092592592592595\n",
      "Epoch #14 iteration #50 loss: 0.23149007558822632\n",
      "Epoch #14 iteration #100 loss: 0.17517328262329102\n",
      "Epoch #14 iteration #150 loss: 0.11628159880638123\n",
      "Epoch #14 iteration #200 loss: 0.16644620895385742\n",
      "Epoch #14 iteration #250 loss: 0.18331921100616455\n",
      "Epoch #14 iteration #300 loss: 0.20259788632392883\n",
      "Epoch #14 iteration #350 loss: 0.1982499659061432\n",
      "Epoch #14 iteration #400 loss: 0.21058139204978943\n",
      "Epoch #14 iteration #450 loss: 0.1868409514427185\n",
      "Epoch #14 iteration #500 loss: 0.12520265579223633\n",
      "Epoch #14 iteration #550 loss: 0.2450299710035324\n",
      "Epoch #14 iteration #600 loss: 0.14054866135120392\n",
      "Epoch #14 iteration #650 loss: 0.31807205080986023\n",
      "Epoch #14 iteration #700 loss: 0.12965898215770721\n",
      "Epoch #14 iteration #750 loss: 0.21084411442279816\n",
      "Epoch #14 iteration #800 loss: 0.19450600445270538\n",
      "Epoch #14 iteration #850 loss: 0.24775975942611694\n",
      "Epoch #14 iteration #900 loss: 0.20159491896629333\n",
      "Epoch #14 iteration #950 loss: 0.16343379020690918\n",
      "Epoch #14 iteration #1000 loss: 0.2095089554786682\n",
      "Epoch #14 iteration #1050 loss: 0.19759619235992432\n",
      "Epoch #14 iteration #1100 loss: 0.18388354778289795\n",
      "Epoch #14 iteration #1150 loss: 0.23581746220588684\n",
      "Epoch #14 iteration #1200 loss: 0.2299591451883316\n",
      "Epoch #14 iteration #1250 loss: 0.17314080893993378\n",
      "Epoch #14 iteration #1300 loss: 0.2520335912704468\n",
      "Epoch #14 iteration #1350 loss: 0.11506509780883789\n",
      "Epoch #14 iteration #1400 loss: 0.19292625784873962\n",
      "Took 8.076 minutes for epoch# 14 to train\n",
      "Epoch #14 Train loss: 0.19991895052440026\n",
      "Epoch #14 Validation Precision: 0.2718253968253968\n",
      "Epoch #15 iteration #50 loss: 0.24850799143314362\n",
      "Epoch #15 iteration #100 loss: 0.16650252044200897\n",
      "Epoch #15 iteration #150 loss: 0.1379404217004776\n",
      "Epoch #15 iteration #200 loss: 0.18212701380252838\n",
      "Epoch #15 iteration #250 loss: 0.18688282370567322\n",
      "Epoch #15 iteration #300 loss: 0.18547752499580383\n",
      "Epoch #15 iteration #350 loss: 0.19262123107910156\n",
      "Epoch #15 iteration #400 loss: 0.2014574259519577\n",
      "Epoch #15 iteration #450 loss: 0.1866457313299179\n",
      "Epoch #15 iteration #500 loss: 0.12124677747488022\n",
      "Epoch #15 iteration #550 loss: 0.24268493056297302\n",
      "Epoch #15 iteration #600 loss: 0.1500180959701538\n",
      "Epoch #15 iteration #650 loss: 0.30912211537361145\n",
      "Epoch #15 iteration #700 loss: 0.11933299899101257\n",
      "Epoch #15 iteration #750 loss: 0.21508413553237915\n",
      "Epoch #15 iteration #800 loss: 0.1970188319683075\n",
      "Epoch #15 iteration #850 loss: 0.20199847221374512\n",
      "Epoch #15 iteration #900 loss: 0.18107739090919495\n",
      "Epoch #15 iteration #950 loss: 0.16513176262378693\n",
      "Epoch #15 iteration #1000 loss: 0.18246082961559296\n",
      "Epoch #15 iteration #1050 loss: 0.190052792429924\n",
      "Epoch #15 iteration #1100 loss: 0.21620629727840424\n",
      "Epoch #15 iteration #1150 loss: 0.22836315631866455\n",
      "Epoch #15 iteration #1200 loss: 0.18280185759067535\n",
      "Epoch #15 iteration #1250 loss: 0.16977250576019287\n",
      "Epoch #15 iteration #1300 loss: 0.26911860704421997\n",
      "Epoch #15 iteration #1350 loss: 0.12755468487739563\n",
      "Epoch #15 iteration #1400 loss: 0.20760005712509155\n",
      "Took 8.035 minutes for epoch# 15 to train\n",
      "Epoch #15 Train loss: 0.1986604010691496\n",
      "Epoch #15 Validation Precision: 0.20702861952861953\n",
      "Epoch #16 iteration #50 loss: 0.22455613315105438\n",
      "Epoch #16 iteration #100 loss: 0.1617092490196228\n",
      "Epoch #16 iteration #150 loss: 0.13089105486869812\n",
      "Epoch #16 iteration #200 loss: 0.1987922489643097\n",
      "Epoch #16 iteration #250 loss: 0.18866458535194397\n",
      "Epoch #16 iteration #300 loss: 0.19023416936397552\n",
      "Epoch #16 iteration #350 loss: 0.17775624990463257\n",
      "Epoch #16 iteration #400 loss: 0.1976056843996048\n",
      "Epoch #16 iteration #450 loss: 0.17862960696220398\n",
      "Epoch #16 iteration #500 loss: 0.13388903439044952\n",
      "Epoch #16 iteration #550 loss: 0.23346270620822906\n",
      "Epoch #16 iteration #600 loss: 0.15458139777183533\n",
      "Epoch #16 iteration #650 loss: 0.3188193738460541\n",
      "Epoch #16 iteration #700 loss: 0.12840427458286285\n",
      "Epoch #16 iteration #750 loss: 0.24343067407608032\n",
      "Epoch #16 iteration #800 loss: 0.18539801239967346\n",
      "Epoch #16 iteration #850 loss: 0.17151930928230286\n",
      "Epoch #16 iteration #900 loss: 0.17392338812351227\n",
      "Epoch #16 iteration #950 loss: 0.1552024632692337\n",
      "Epoch #16 iteration #1000 loss: 0.18639789521694183\n",
      "Epoch #16 iteration #1050 loss: 0.20236743986606598\n",
      "Epoch #16 iteration #1100 loss: 0.1874733865261078\n",
      "Epoch #16 iteration #1150 loss: 0.24253243207931519\n",
      "Epoch #16 iteration #1200 loss: 0.21651498973369598\n",
      "Epoch #16 iteration #1250 loss: 0.19829101860523224\n",
      "Epoch #16 iteration #1300 loss: 0.2562119960784912\n",
      "Epoch #16 iteration #1350 loss: 0.1385762095451355\n",
      "Epoch #16 iteration #1400 loss: 0.16182823479175568\n",
      "Took 8.077 minutes for epoch# 16 to train\n",
      "Epoch #16 Train loss: 0.19833210080924654\n",
      "Epoch #16 Validation Precision: 0.19819023569023567\n",
      "Epoch #17 iteration #50 loss: 0.2544446885585785\n",
      "Epoch #17 iteration #100 loss: 0.17034275829792023\n",
      "Epoch #17 iteration #150 loss: 0.09609777480363846\n",
      "Epoch #17 iteration #200 loss: 0.19969205558300018\n",
      "Epoch #17 iteration #250 loss: 0.1753205806016922\n",
      "Epoch #17 iteration #300 loss: 0.17092427611351013\n",
      "Epoch #17 iteration #350 loss: 0.19840015470981598\n",
      "Epoch #17 iteration #400 loss: 0.22249750792980194\n",
      "Epoch #17 iteration #450 loss: 0.18523551523685455\n",
      "Epoch #17 iteration #500 loss: 0.11808087676763535\n",
      "Epoch #17 iteration #550 loss: 0.24003881216049194\n",
      "Epoch #17 iteration #600 loss: 0.14190052449703217\n",
      "Epoch #17 iteration #650 loss: 0.2935827076435089\n",
      "Epoch #17 iteration #700 loss: 0.12315478175878525\n",
      "Epoch #17 iteration #750 loss: 0.24569407105445862\n",
      "Epoch #17 iteration #800 loss: 0.17043536901474\n",
      "Epoch #17 iteration #850 loss: 0.21657797694206238\n",
      "Epoch #17 iteration #900 loss: 0.1877848207950592\n",
      "Epoch #17 iteration #950 loss: 0.15311101078987122\n",
      "Epoch #17 iteration #1000 loss: 0.20717182755470276\n",
      "Epoch #17 iteration #1050 loss: 0.19180645048618317\n",
      "Epoch #17 iteration #1100 loss: 0.18236100673675537\n",
      "Epoch #17 iteration #1150 loss: 0.27297669649124146\n",
      "Epoch #17 iteration #1200 loss: 0.18522948026657104\n",
      "Epoch #17 iteration #1250 loss: 0.17929667234420776\n",
      "Epoch #17 iteration #1300 loss: 0.2795199155807495\n",
      "Epoch #17 iteration #1350 loss: 0.12495283037424088\n",
      "Epoch #17 iteration #1400 loss: 0.17738232016563416\n",
      "Took 8.074 minutes for epoch# 17 to train\n",
      "Epoch #17 Train loss: 0.19789697569521034\n",
      "Epoch #17 Validation Precision: 0.18863636363636366\n",
      "Epoch #18 iteration #50 loss: 0.21372796595096588\n",
      "Epoch #18 iteration #100 loss: 0.1749100238084793\n",
      "Epoch #18 iteration #150 loss: 0.12255708873271942\n",
      "Epoch #18 iteration #200 loss: 0.2007017582654953\n",
      "Epoch #18 iteration #250 loss: 0.19820931553840637\n",
      "Epoch #18 iteration #300 loss: 0.18396760523319244\n",
      "Epoch #18 iteration #350 loss: 0.1922214776277542\n",
      "Epoch #18 iteration #400 loss: 0.2307622730731964\n",
      "Epoch #18 iteration #450 loss: 0.20093759894371033\n",
      "Epoch #18 iteration #500 loss: 0.11371229588985443\n",
      "Epoch #18 iteration #550 loss: 0.25963979959487915\n",
      "Epoch #18 iteration #600 loss: 0.14210408926010132\n",
      "Epoch #18 iteration #650 loss: 0.27135181427001953\n",
      "Epoch #18 iteration #700 loss: 0.12857787311077118\n",
      "Epoch #18 iteration #750 loss: 0.22444239258766174\n",
      "Epoch #18 iteration #800 loss: 0.2230043262243271\n",
      "Epoch #18 iteration #850 loss: 0.1821528673171997\n",
      "Epoch #18 iteration #900 loss: 0.18045832216739655\n",
      "Epoch #18 iteration #950 loss: 0.17048588395118713\n",
      "Epoch #18 iteration #1000 loss: 0.19094443321228027\n",
      "Epoch #18 iteration #1050 loss: 0.18682314455509186\n",
      "Epoch #18 iteration #1100 loss: 0.20086628198623657\n",
      "Epoch #18 iteration #1150 loss: 0.23183615505695343\n",
      "Epoch #18 iteration #1200 loss: 0.19276143610477448\n",
      "Epoch #18 iteration #1250 loss: 0.20028145611286163\n",
      "Epoch #18 iteration #1300 loss: 0.2819174826145172\n",
      "Epoch #18 iteration #1350 loss: 0.11936065554618835\n",
      "Epoch #18 iteration #1400 loss: 0.21133175492286682\n",
      "Took 8.076 minutes for epoch# 18 to train\n",
      "Epoch #18 Train loss: 0.1968107339391271\n",
      "Epoch #18 Validation Precision: 0.24186507936507934\n",
      "Epoch #19 iteration #50 loss: 0.2222137451171875\n",
      "Epoch #19 iteration #100 loss: 0.17283016443252563\n",
      "Epoch #19 iteration #150 loss: 0.11550199240446091\n",
      "Epoch #19 iteration #200 loss: 0.20041601359844208\n",
      "Epoch #19 iteration #250 loss: 0.18888477981090546\n",
      "Epoch #19 iteration #300 loss: 0.15794017910957336\n",
      "Epoch #19 iteration #350 loss: 0.2047509402036667\n",
      "Epoch #19 iteration #400 loss: 0.19189263880252838\n",
      "Epoch #19 iteration #450 loss: 0.21720603108406067\n",
      "Epoch #19 iteration #500 loss: 0.12834282219409943\n",
      "Epoch #19 iteration #550 loss: 0.24707649648189545\n",
      "Epoch #19 iteration #600 loss: 0.12785407900810242\n",
      "Epoch #19 iteration #650 loss: 0.2630476653575897\n",
      "Epoch #19 iteration #700 loss: 0.12215275317430496\n",
      "Epoch #19 iteration #750 loss: 0.2412218153476715\n",
      "Epoch #19 iteration #800 loss: 0.2031441181898117\n",
      "Epoch #19 iteration #850 loss: 0.2037653923034668\n",
      "Epoch #19 iteration #900 loss: 0.19626960158348083\n",
      "Epoch #19 iteration #950 loss: 0.15980446338653564\n",
      "Epoch #19 iteration #1000 loss: 0.20059847831726074\n",
      "Epoch #19 iteration #1050 loss: 0.17897270619869232\n",
      "Epoch #19 iteration #1100 loss: 0.1976945549249649\n",
      "Epoch #19 iteration #1150 loss: 0.2773015797138214\n",
      "Epoch #19 iteration #1200 loss: 0.20445320010185242\n",
      "Epoch #19 iteration #1250 loss: 0.1838318407535553\n",
      "Epoch #19 iteration #1300 loss: 0.3126763105392456\n",
      "Epoch #19 iteration #1350 loss: 0.14440307021141052\n",
      "Epoch #19 iteration #1400 loss: 0.18606175482273102\n",
      "Took 8.062 minutes for epoch# 19 to train\n",
      "Epoch #19 Train loss: 0.19537573524800336\n",
      "Epoch #19 Validation Precision: 0.29712301587301587\n",
      "Epoch #20 iteration #50 loss: 0.22007668018341064\n",
      "Epoch #20 iteration #100 loss: 0.18319196999073029\n",
      "Epoch #20 iteration #150 loss: 0.13260042667388916\n",
      "Epoch #20 iteration #200 loss: 0.17751960456371307\n",
      "Epoch #20 iteration #250 loss: 0.17195220291614532\n",
      "Epoch #20 iteration #300 loss: 0.17556411027908325\n",
      "Epoch #20 iteration #350 loss: 0.19379039108753204\n",
      "Epoch #20 iteration #400 loss: 0.20387527346611023\n",
      "Epoch #20 iteration #450 loss: 0.19414979219436646\n",
      "Epoch #20 iteration #500 loss: 0.13041752576828003\n",
      "Epoch #20 iteration #550 loss: 0.22720476984977722\n",
      "Epoch #20 iteration #600 loss: 0.14102701842784882\n",
      "Epoch #20 iteration #650 loss: 0.3182823657989502\n",
      "Epoch #20 iteration #700 loss: 0.11715911328792572\n",
      "Epoch #20 iteration #750 loss: 0.24235820770263672\n",
      "Epoch #20 iteration #800 loss: 0.17294031381607056\n",
      "Epoch #20 iteration #850 loss: 0.18832240998744965\n",
      "Epoch #20 iteration #900 loss: 0.21741744875907898\n",
      "Epoch #20 iteration #950 loss: 0.16057685017585754\n",
      "Epoch #20 iteration #1000 loss: 0.21034176647663116\n",
      "Epoch #20 iteration #1050 loss: 0.17503148317337036\n",
      "Epoch #20 iteration #1100 loss: 0.18745070695877075\n",
      "Epoch #20 iteration #1150 loss: 0.2616555094718933\n",
      "Epoch #20 iteration #1200 loss: 0.1796518713235855\n",
      "Epoch #20 iteration #1250 loss: 0.19154036045074463\n",
      "Epoch #20 iteration #1300 loss: 0.28119438886642456\n",
      "Epoch #20 iteration #1350 loss: 0.11598575860261917\n",
      "Epoch #20 iteration #1400 loss: 0.17577138543128967\n",
      "Took 8.040 minutes for epoch# 20 to train\n",
      "Epoch #20 Train loss: 0.19541689558919906\n",
      "Epoch #20 Validation Precision: 0.22685185185185186\n",
      "Epoch #21 iteration #50 loss: 0.23725152015686035\n",
      "Epoch #21 iteration #100 loss: 0.17530280351638794\n",
      "Epoch #21 iteration #150 loss: 0.10847033560276031\n",
      "Epoch #21 iteration #200 loss: 0.17358288168907166\n",
      "Epoch #21 iteration #250 loss: 0.15779724717140198\n",
      "Epoch #21 iteration #300 loss: 0.17262057960033417\n",
      "Epoch #21 iteration #350 loss: 0.196453258395195\n",
      "Epoch #21 iteration #400 loss: 0.21012651920318604\n",
      "Epoch #21 iteration #450 loss: 0.18960051238536835\n",
      "Epoch #21 iteration #500 loss: 0.11290769279003143\n",
      "Epoch #21 iteration #550 loss: 0.25055304169654846\n",
      "Epoch #21 iteration #600 loss: 0.13936640322208405\n",
      "Epoch #21 iteration #650 loss: 0.2990376055240631\n",
      "Epoch #21 iteration #700 loss: 0.11979518830776215\n",
      "Epoch #21 iteration #750 loss: 0.24725744128227234\n",
      "Epoch #21 iteration #800 loss: 0.15786994993686676\n",
      "Epoch #21 iteration #850 loss: 0.19214312732219696\n",
      "Epoch #21 iteration #900 loss: 0.19070516526699066\n",
      "Epoch #21 iteration #950 loss: 0.13792574405670166\n",
      "Epoch #21 iteration #1000 loss: 0.17101141810417175\n",
      "Epoch #21 iteration #1050 loss: 0.1912849396467209\n",
      "Epoch #21 iteration #1100 loss: 0.19156388938426971\n",
      "Epoch #21 iteration #1150 loss: 0.21283850073814392\n",
      "Epoch #21 iteration #1200 loss: 0.18007811903953552\n",
      "Epoch #21 iteration #1250 loss: 0.18370434641838074\n",
      "Epoch #21 iteration #1300 loss: 0.2415391355752945\n",
      "Epoch #21 iteration #1350 loss: 0.12735232710838318\n",
      "Epoch #21 iteration #1400 loss: 0.1893821358680725\n",
      "Took 8.046 minutes for epoch# 21 to train\n",
      "Epoch #21 Train loss: 0.19442135308991795\n",
      "Epoch #21 Validation Precision: 0.2785714285714286\n",
      "Epoch #22 iteration #50 loss: 0.22069570422172546\n",
      "Epoch #22 iteration #100 loss: 0.1712808459997177\n",
      "Epoch #22 iteration #150 loss: 0.1120438277721405\n",
      "Epoch #22 iteration #200 loss: 0.18597380816936493\n",
      "Epoch #22 iteration #250 loss: 0.1707693189382553\n",
      "Epoch #22 iteration #300 loss: 0.17144761979579926\n",
      "Epoch #22 iteration #350 loss: 0.20546850562095642\n",
      "Epoch #22 iteration #400 loss: 0.1977827101945877\n",
      "Epoch #22 iteration #450 loss: 0.18827936053276062\n",
      "Epoch #22 iteration #500 loss: 0.1111045554280281\n",
      "Epoch #22 iteration #550 loss: 0.28531190752983093\n",
      "Epoch #22 iteration #600 loss: 0.16138404607772827\n",
      "Epoch #22 iteration #650 loss: 0.29272353649139404\n",
      "Epoch #22 iteration #700 loss: 0.1193874403834343\n",
      "Epoch #22 iteration #750 loss: 0.23872214555740356\n",
      "Epoch #22 iteration #800 loss: 0.15664026141166687\n",
      "Epoch #22 iteration #850 loss: 0.21579501032829285\n",
      "Epoch #22 iteration #900 loss: 0.20235896110534668\n",
      "Epoch #22 iteration #950 loss: 0.14011512696743011\n",
      "Epoch #22 iteration #1000 loss: 0.18853330612182617\n",
      "Epoch #22 iteration #1050 loss: 0.1815595179796219\n",
      "Epoch #22 iteration #1100 loss: 0.20530658960342407\n",
      "Epoch #22 iteration #1150 loss: 0.22033171355724335\n",
      "Epoch #22 iteration #1200 loss: 0.18285608291625977\n",
      "Epoch #22 iteration #1250 loss: 0.1886739581823349\n",
      "Epoch #22 iteration #1300 loss: 0.26646724343299866\n",
      "Epoch #22 iteration #1350 loss: 0.12310218811035156\n",
      "Epoch #22 iteration #1400 loss: 0.1870669573545456\n",
      "Took 8.045 minutes for epoch# 22 to train\n",
      "Epoch #22 Train loss: 0.1933494743627577\n",
      "Epoch #22 Validation Precision: 0.22361111111111112\n",
      "Epoch #23 iteration #50 loss: 0.2226647436618805\n",
      "Epoch #23 iteration #100 loss: 0.16532227396965027\n",
      "Epoch #23 iteration #150 loss: 0.13557234406471252\n",
      "Epoch #23 iteration #200 loss: 0.18518571555614471\n",
      "Epoch #23 iteration #250 loss: 0.17546875774860382\n",
      "Epoch #23 iteration #300 loss: 0.17917409539222717\n",
      "Epoch #23 iteration #350 loss: 0.20403306186199188\n",
      "Epoch #23 iteration #400 loss: 0.20310424268245697\n",
      "Epoch #23 iteration #450 loss: 0.18552935123443604\n",
      "Epoch #23 iteration #500 loss: 0.09984324127435684\n",
      "Epoch #23 iteration #550 loss: 0.24283641576766968\n",
      "Epoch #23 iteration #600 loss: 0.11422102898359299\n",
      "Epoch #23 iteration #650 loss: 0.2716869115829468\n",
      "Epoch #23 iteration #700 loss: 0.13105694949626923\n",
      "Epoch #23 iteration #750 loss: 0.23789452016353607\n",
      "Epoch #23 iteration #800 loss: 0.1915774941444397\n",
      "Epoch #23 iteration #850 loss: 0.19216474890708923\n",
      "Epoch #23 iteration #900 loss: 0.17725661396980286\n",
      "Epoch #23 iteration #950 loss: 0.1708107739686966\n",
      "Epoch #23 iteration #1000 loss: 0.17820098996162415\n",
      "Epoch #23 iteration #1050 loss: 0.18194344639778137\n",
      "Epoch #23 iteration #1100 loss: 0.1842726618051529\n",
      "Epoch #23 iteration #1150 loss: 0.23685915768146515\n",
      "Epoch #23 iteration #1200 loss: 0.19758547842502594\n",
      "Epoch #23 iteration #1250 loss: 0.2071690410375595\n",
      "Epoch #23 iteration #1300 loss: 0.23528024554252625\n",
      "Epoch #23 iteration #1350 loss: 0.12019429355859756\n",
      "Epoch #23 iteration #1400 loss: 0.1668059080839157\n",
      "Took 8.052 minutes for epoch# 23 to train\n",
      "Epoch #23 Train loss: 0.19373111963188616\n",
      "Epoch #23 Validation Precision: 0.24732142857142855\n",
      "Epoch #24 iteration #50 loss: 0.23103812336921692\n",
      "Epoch #24 iteration #100 loss: 0.17110607028007507\n",
      "Epoch #24 iteration #150 loss: 0.16981203854084015\n",
      "Epoch #24 iteration #200 loss: 0.19236904382705688\n",
      "Epoch #24 iteration #250 loss: 0.18865445256233215\n",
      "Epoch #24 iteration #300 loss: 0.17091134190559387\n",
      "Epoch #24 iteration #350 loss: 0.200996994972229\n",
      "Epoch #24 iteration #400 loss: 0.19597658514976501\n",
      "Epoch #24 iteration #450 loss: 0.19166725873947144\n",
      "Epoch #24 iteration #500 loss: 0.12392591685056686\n",
      "Epoch #24 iteration #550 loss: 0.25114044547080994\n",
      "Epoch #24 iteration #600 loss: 0.14646470546722412\n",
      "Epoch #24 iteration #650 loss: 0.27615752816200256\n",
      "Epoch #24 iteration #700 loss: 0.12013283371925354\n",
      "Epoch #24 iteration #750 loss: 0.23062686622142792\n",
      "Epoch #24 iteration #800 loss: 0.18210925161838531\n",
      "Epoch #24 iteration #850 loss: 0.17435936629772186\n",
      "Epoch #24 iteration #900 loss: 0.20902082324028015\n",
      "Epoch #24 iteration #950 loss: 0.1602618247270584\n",
      "Epoch #24 iteration #1000 loss: 0.17643669247627258\n",
      "Epoch #24 iteration #1050 loss: 0.17785659432411194\n",
      "Epoch #24 iteration #1100 loss: 0.16764381527900696\n",
      "Epoch #24 iteration #1150 loss: 0.2198050320148468\n",
      "Epoch #24 iteration #1200 loss: 0.24777095019817352\n",
      "Epoch #24 iteration #1250 loss: 0.18798546493053436\n",
      "Epoch #24 iteration #1300 loss: 0.255214124917984\n",
      "Epoch #24 iteration #1350 loss: 0.12603235244750977\n",
      "Epoch #24 iteration #1400 loss: 0.2009768933057785\n",
      "Took 8.057 minutes for epoch# 24 to train\n",
      "Epoch #24 Train loss: 0.1933362467647517\n",
      "Epoch #24 Validation Precision: 0.27519841269841266\n",
      "Epoch #25 iteration #50 loss: 0.25689104199409485\n",
      "Epoch #25 iteration #100 loss: 0.16839927434921265\n",
      "Epoch #25 iteration #150 loss: 0.12087530642747879\n",
      "Epoch #25 iteration #200 loss: 0.18984192609786987\n",
      "Epoch #25 iteration #250 loss: 0.1678592562675476\n",
      "Epoch #25 iteration #300 loss: 0.18244564533233643\n",
      "Epoch #25 iteration #350 loss: 0.2087518721818924\n",
      "Epoch #25 iteration #400 loss: 0.21748055517673492\n",
      "Epoch #25 iteration #450 loss: 0.18507665395736694\n",
      "Epoch #25 iteration #500 loss: 0.11430133879184723\n",
      "Epoch #25 iteration #550 loss: 0.2558574080467224\n",
      "Epoch #25 iteration #600 loss: 0.13405944406986237\n",
      "Epoch #25 iteration #650 loss: 0.261620432138443\n",
      "Epoch #25 iteration #700 loss: 0.13343527913093567\n",
      "Epoch #25 iteration #750 loss: 0.26084059476852417\n",
      "Epoch #25 iteration #800 loss: 0.17065714299678802\n",
      "Epoch #25 iteration #850 loss: 0.22718945145606995\n",
      "Epoch #25 iteration #900 loss: 0.19938316941261292\n",
      "Epoch #25 iteration #950 loss: 0.16753683984279633\n",
      "Epoch #25 iteration #1000 loss: 0.17806194722652435\n",
      "Epoch #25 iteration #1050 loss: 0.20227941870689392\n",
      "Epoch #25 iteration #1100 loss: 0.1922309398651123\n",
      "Epoch #25 iteration #1150 loss: 0.2543596923351288\n",
      "Epoch #25 iteration #1200 loss: 0.2077101320028305\n",
      "Epoch #25 iteration #1250 loss: 0.20567604899406433\n",
      "Epoch #25 iteration #1300 loss: 0.24907253682613373\n",
      "Epoch #25 iteration #1350 loss: 0.12886062264442444\n",
      "Epoch #25 iteration #1400 loss: 0.19847209751605988\n",
      "Took 8.044 minutes for epoch# 25 to train\n",
      "Epoch #25 Train loss: 0.19278475381329613\n",
      "Epoch #25 Validation Precision: 0.26825396825396824\n",
      "Epoch #26 iteration #50 loss: 0.2279524952173233\n",
      "Epoch #26 iteration #100 loss: 0.16362670063972473\n",
      "Epoch #26 iteration #150 loss: 0.11809669435024261\n",
      "Epoch #26 iteration #200 loss: 0.18688009679317474\n",
      "Epoch #26 iteration #250 loss: 0.19612599909305573\n",
      "Epoch #26 iteration #300 loss: 0.190951868891716\n",
      "Epoch #26 iteration #350 loss: 0.2021685242652893\n",
      "Epoch #26 iteration #400 loss: 0.16692808270454407\n",
      "Epoch #26 iteration #450 loss: 0.17420314252376556\n",
      "Epoch #26 iteration #500 loss: 0.1141069233417511\n",
      "Epoch #26 iteration #550 loss: 0.25925707817077637\n",
      "Epoch #26 iteration #600 loss: 0.11852313578128815\n",
      "Epoch #26 iteration #650 loss: 0.29146334528923035\n",
      "Epoch #26 iteration #700 loss: 0.12351404875516891\n",
      "Epoch #26 iteration #750 loss: 0.24000853300094604\n",
      "Epoch #26 iteration #800 loss: 0.1665889173746109\n",
      "Epoch #26 iteration #850 loss: 0.19511359930038452\n",
      "Epoch #26 iteration #900 loss: 0.19401147961616516\n",
      "Epoch #26 iteration #950 loss: 0.1571965366601944\n",
      "Epoch #26 iteration #1000 loss: 0.19356007874011993\n",
      "Epoch #26 iteration #1050 loss: 0.16619814932346344\n",
      "Epoch #26 iteration #1100 loss: 0.1880556344985962\n",
      "Epoch #26 iteration #1150 loss: 0.271261990070343\n",
      "Epoch #26 iteration #1200 loss: 0.19740203022956848\n",
      "Epoch #26 iteration #1250 loss: 0.18415296077728271\n",
      "Epoch #26 iteration #1300 loss: 0.2523127496242523\n",
      "Epoch #26 iteration #1350 loss: 0.11857081949710846\n",
      "Epoch #26 iteration #1400 loss: 0.19756875932216644\n",
      "Took 8.052 minutes for epoch# 26 to train\n",
      "Epoch #26 Train loss: 0.19149334599845716\n",
      "Epoch #26 Validation Precision: 0.2214781746031746\n",
      "Epoch #27 iteration #50 loss: 0.21950018405914307\n",
      "Epoch #27 iteration #100 loss: 0.174740269780159\n",
      "Epoch #27 iteration #150 loss: 0.11721554398536682\n",
      "Epoch #27 iteration #200 loss: 0.1706254929304123\n",
      "Epoch #27 iteration #250 loss: 0.16436529159545898\n",
      "Epoch #27 iteration #300 loss: 0.1673445850610733\n",
      "Epoch #27 iteration #350 loss: 0.19371411204338074\n",
      "Epoch #27 iteration #400 loss: 0.18615685403347015\n",
      "Epoch #27 iteration #450 loss: 0.1606234312057495\n",
      "Epoch #27 iteration #500 loss: 0.11647596210241318\n",
      "Epoch #27 iteration #550 loss: 0.2580151855945587\n",
      "Epoch #27 iteration #600 loss: 0.13079772889614105\n",
      "Epoch #27 iteration #650 loss: 0.29633110761642456\n",
      "Epoch #27 iteration #700 loss: 0.1175546869635582\n",
      "Epoch #27 iteration #750 loss: 0.22956718504428864\n",
      "Epoch #27 iteration #800 loss: 0.17143428325653076\n",
      "Epoch #27 iteration #850 loss: 0.18068572878837585\n",
      "Epoch #27 iteration #900 loss: 0.17801687121391296\n",
      "Epoch #27 iteration #950 loss: 0.14209988713264465\n",
      "Epoch #27 iteration #1000 loss: 0.19014376401901245\n",
      "Epoch #27 iteration #1050 loss: 0.16765734553337097\n",
      "Epoch #27 iteration #1100 loss: 0.19299954175949097\n",
      "Epoch #27 iteration #1150 loss: 0.24321158230304718\n",
      "Epoch #27 iteration #1200 loss: 0.19430284202098846\n",
      "Epoch #27 iteration #1250 loss: 0.2139311283826828\n",
      "Epoch #27 iteration #1300 loss: 0.23000375926494598\n",
      "Epoch #27 iteration #1350 loss: 0.12817580997943878\n",
      "Epoch #27 iteration #1400 loss: 0.18210428953170776\n",
      "Took 8.104 minutes for epoch# 27 to train\n",
      "Epoch #27 Train loss: 0.18975733930156344\n",
      "Epoch #27 Validation Precision: 0.2455266955266955\n",
      "Epoch #28 iteration #50 loss: 0.22792844474315643\n",
      "Epoch #28 iteration #100 loss: 0.16768208146095276\n",
      "Epoch #28 iteration #150 loss: 0.09615633636713028\n",
      "Epoch #28 iteration #200 loss: 0.17890870571136475\n",
      "Epoch #28 iteration #250 loss: 0.1553068906068802\n",
      "Epoch #28 iteration #300 loss: 0.1707315444946289\n",
      "Epoch #28 iteration #350 loss: 0.19872649013996124\n",
      "Epoch #28 iteration #400 loss: 0.1893405318260193\n",
      "Epoch #28 iteration #450 loss: 0.16315965354442596\n",
      "Epoch #28 iteration #500 loss: 0.1100931465625763\n",
      "Epoch #28 iteration #550 loss: 0.21720246970653534\n",
      "Epoch #28 iteration #600 loss: 0.13532914221286774\n",
      "Epoch #28 iteration #650 loss: 0.27906590700149536\n",
      "Epoch #28 iteration #700 loss: 0.10965827852487564\n",
      "Epoch #28 iteration #750 loss: 0.2585484981536865\n",
      "Epoch #28 iteration #800 loss: 0.15212345123291016\n",
      "Epoch #28 iteration #850 loss: 0.19509828090667725\n",
      "Epoch #28 iteration #900 loss: 0.19319303333759308\n",
      "Epoch #28 iteration #950 loss: 0.167756587266922\n",
      "Epoch #28 iteration #1000 loss: 0.19092170894145966\n",
      "Epoch #28 iteration #1050 loss: 0.17445412278175354\n",
      "Epoch #28 iteration #1100 loss: 0.1831345409154892\n",
      "Epoch #28 iteration #1150 loss: 0.21445533633232117\n",
      "Epoch #28 iteration #1200 loss: 0.18903040885925293\n",
      "Epoch #28 iteration #1250 loss: 0.17333681881427765\n",
      "Epoch #28 iteration #1300 loss: 0.22441107034683228\n",
      "Epoch #28 iteration #1350 loss: 0.13036830723285675\n",
      "Epoch #28 iteration #1400 loss: 0.2034573256969452\n",
      "Took 8.053 minutes for epoch# 28 to train\n",
      "Epoch #28 Train loss: 0.18861467932306586\n",
      "Epoch #28 Validation Precision: 0.2575396825396825\n",
      "Epoch #29 iteration #50 loss: 0.23925800621509552\n",
      "Epoch #29 iteration #100 loss: 0.17047765851020813\n",
      "Epoch #29 iteration #150 loss: 0.08157741278409958\n",
      "Epoch #29 iteration #200 loss: 0.17046014964580536\n",
      "Epoch #29 iteration #250 loss: 0.15612246096134186\n",
      "Epoch #29 iteration #300 loss: 0.1681240350008011\n",
      "Epoch #29 iteration #350 loss: 0.1891203671693802\n",
      "Epoch #29 iteration #400 loss: 0.1792302429676056\n",
      "Epoch #29 iteration #450 loss: 0.1707623451948166\n",
      "Epoch #29 iteration #500 loss: 0.11679396033287048\n",
      "Epoch #29 iteration #550 loss: 0.2455822080373764\n",
      "Epoch #29 iteration #600 loss: 0.15682753920555115\n",
      "Epoch #29 iteration #650 loss: 0.30740588903427124\n",
      "Epoch #29 iteration #700 loss: 0.11831853538751602\n",
      "Epoch #29 iteration #750 loss: 0.22297410666942596\n",
      "Epoch #29 iteration #800 loss: 0.16086354851722717\n",
      "Epoch #29 iteration #850 loss: 0.20287077128887177\n",
      "Epoch #29 iteration #900 loss: 0.2147933393716812\n",
      "Epoch #29 iteration #950 loss: 0.15555912256240845\n",
      "Epoch #29 iteration #1000 loss: 0.1772686392068863\n",
      "Epoch #29 iteration #1050 loss: 0.1814880669116974\n",
      "Epoch #29 iteration #1100 loss: 0.18483585119247437\n",
      "Epoch #29 iteration #1150 loss: 0.22766058146953583\n",
      "Epoch #29 iteration #1200 loss: 0.18978582322597504\n",
      "Epoch #29 iteration #1250 loss: 0.17085902392864227\n",
      "Epoch #29 iteration #1300 loss: 0.26310229301452637\n",
      "Epoch #29 iteration #1350 loss: 0.11727443337440491\n",
      "Epoch #29 iteration #1400 loss: 0.19190983474254608\n",
      "Took 8.042 minutes for epoch# 29 to train\n",
      "Epoch #29 Train loss: 0.18864226334986567\n",
      "Epoch #29 Validation Precision: 0.33935185185185185\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "!python train.py --show-sample yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T17:53:34.872554Z",
     "start_time": "2020-12-04T17:53:34.742696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec  5 01:53:34 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.59       Driver Version: 440.59       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 25%   28C    P8     1W / 260W |    462MiB / 11016MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1280      G   /usr/lib/xorg/Xorg                           129MiB |\r\n",
      "|    0      1515      G   /usr/bin/gnome-shell                         176MiB |\r\n",
      "|    0      2159      G   ...AAAAAAAAAAAAAAgAAAAAAAAA --shared-files   154MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile test.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import albumentations as A\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from PIL import Image\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "DIR_INPUT = '../input/rsna-pneumonia-detection-2018/input'\n",
    "DIR_TEST = f\"{DIR_INPUT}/samples\"\n",
    "test_images = os.listdir(DIR_TEST)\n",
    "print(f\"Validation instances: {len(test_images)}\")\n",
    "\n",
    "# load a model; pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, min_size=1024)\n",
    "num_classes = 2  # 1 class (pnueomonia) + background\n",
    "# get the number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "os.makedirs('../validation_predictions', exist_ok=True)\n",
    "model.load_state_dict(torch.load('../input/rsna-pytorch-hackathon-fasterrcnn-resnet-training/fasterrcnn_resnet50_fpn.pth'))\n",
    "model.to(device)\n",
    "\n",
    "def format_prediction_string(boxes, scores):\n",
    "    pred_strings = []\n",
    "    for j in zip(scores, boxes):\n",
    "        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], \n",
    "                                                             int(j[1][0]), int(j[1][1]), \n",
    "                                                             int(j[1][2]), int(j[1][3])))\n",
    "\n",
    "    return \" \".join(pred_strings)\n",
    "\n",
    "detection_threshold = 0.9\n",
    "img_num = 0\n",
    "results = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, image in tqdm(enumerate(test_images), total=len(test_images)):\n",
    "\n",
    "        orig_image = cv2.imread(f\"{DIR_TEST}/{test_images[i]}\", cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float)\n",
    "        image = torch.tensor(image, dtype=torch.float).cuda()\n",
    "        image = torch.unsqueeze(image, 0)\n",
    "\n",
    "        model.eval()\n",
    "        cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "        outputs = model(image)\n",
    "        \n",
    "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "        if len(outputs[0]['boxes']) != 0:\n",
    "            for counter in range(len(outputs[0]['boxes'])):\n",
    "                boxes = outputs[0]['boxes'].data.cpu().numpy()\n",
    "                scores = outputs[0]['scores'].data.cpu().numpy()\n",
    "                boxes = boxes[scores >= detection_threshold].astype(np.int32)\n",
    "                draw_boxes = boxes.copy()\n",
    "                boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "                boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "                \n",
    "            for box in draw_boxes:\n",
    "                cv2.rectangle(orig_image,\n",
    "                            (int(box[0]), int(box[1])),\n",
    "                            (int(box[2]), int(box[3])),\n",
    "                            (0, 0, 255), 3)\n",
    "        \n",
    "            plt.imshow(cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis('off')\n",
    "            plt.savefig(f\"{test_images[i]}\")\n",
    "            plt.close()\n",
    "                \n",
    "            result = {\n",
    "                'patientId': test_images[i].split('.')[0],\n",
    "                'PredictionString': format_prediction_string(boxes, scores)\n",
    "            }\n",
    "            results.append(result)\n",
    "        else:\n",
    "            result = {\n",
    "                'patientId': test_images[i].split('.')[0],\n",
    "                'PredictionString': None\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "sub_df = pd.DataFrame(results, columns=['patientId', 'PredictionString'])\n",
    "print(sub_df.head())\n",
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
